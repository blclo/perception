{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "e9951489-b2a6-46d4-afa6-276038824bbf",
    "deepnote_cell_height": 138,
    "deepnote_cell_type": "code",
    "owner_user_id": "6194dae6-c2f0-4b3e-a7ec-97523b51ec84"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from PIL import Image, ImageChops, ImageOps\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_empty = Image.open(\"./../Data/Stereo_conveyor_without_occlusions_undistorted/left/1585434280_502471924_Left.png\")\n",
    "img_empty = ImageOps.grayscale(img_empty)\n",
    "folder = \"./../Data/Stereo_conveyor_without_occlusions_undistorted/left\"\n",
    "cropped_images = []\n",
    "images = []\n",
    "class_names = ['Book', 'Box', 'Cup']\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (50, 50)\n",
    "fontScale = 1\n",
    "color = (0, 0, 0)\n",
    "thickness = 3\n",
    "model = keras.models.load_model(\"./../Models/CNN_1.kerasave\")\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    img = Image.open(os.path.join(folder, filename))\n",
    "    img_gray = ImageOps.grayscale(img)\n",
    "    \n",
    "    \n",
    "    # finding differences\n",
    "    diff = ImageChops.difference(img_empty, img_gray)\n",
    "    diff_np = np.array(diff)\n",
    "    \n",
    "    ret,thresh1 = cv2.threshold(diff_np,20,255,cv2.THRESH_BINARY)\n",
    "    # Morphological operations to delete unwanted small areas\n",
    "    kernel = np.ones((10,10), np.uint8)\n",
    "    img_erosion = cv2.erode(thresh1, kernel, iterations = 1)\n",
    "    img_dilation = cv2.dilate(img_erosion, kernel, iterations = 1)\n",
    "    \n",
    "    #cut\n",
    "    img_dilation[0:720, 0:330] = 0\n",
    "    img_dilation[0:720, 1100:1280] = 0\n",
    "    img_dilation[600:720, 0:1280] = 0\n",
    "\n",
    "    # create rectangle around the object\n",
    "    img = np.array(img)\n",
    "    #img = keras.preprocessing.image.img_to_array(img)\n",
    "    coords = cv2.findNonZero(img_dilation)\n",
    "    x,y,w,h = cv2.boundingRect(coords)\n",
    "    if (img is not None) and (w < 400) and (w > 50) and (h < 400) and (h > 50):\n",
    "        rec = cv2.rectangle(img, (x-40,y-25), (x+w+25,y+h+25), (0,255,0), 4)\n",
    "        x_start = x - 40\n",
    "        x_end = x + w +20\n",
    "        y_start = y-20\n",
    "        y_end = y + h+20\n",
    "        if x_start < 0:\n",
    "            x_start = 0\n",
    "        if x_end > img_gray.size[0]:\n",
    "            x_end = img_gray.size[0]\n",
    "        if y_start < 0: \n",
    "            y_start = 0\n",
    "        if y_end > img_gray.size[1]:\n",
    "            y_end =  img_gray.size[1]\n",
    "\n",
    "    \n",
    "        img_crop = img[y_start:y_end,x_start:x_end]\n",
    "  \n",
    "        img_crop = cv2.resize(img_crop,(180,180), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "        img_array = tf.expand_dims(img_crop, 0)\n",
    "    \n",
    "        predictions = model.predict(img_array)\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "        class_predict = class_names[np.argmax(score)]\n",
    "        text = \"Detected object: \" + class_predict\n",
    "    else:\n",
    "        rec = img\n",
    "        text = \"Detected object: None\"\n",
    "    \n",
    "    \n",
    "    if (rec is not None):\n",
    "        image = cv2.putText(rec, text, org, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        images.append(image) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as video\n",
    "\n",
    "out = cv2.VideoWriter('./../Output/Classifier.avi',cv2.VideoWriter_fourcc(*'DIVX') , 15, (images[1].shape[1], images[1].shape[0]))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    out.write(images[i])\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=7012705b-60eb-4206-a7ec-0352216dd398' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "13d492f0-2dfb-4240-9378-8961605adff1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
