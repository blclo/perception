{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow:\n",
    "- Open the rectified image set\n",
    "- Perform BackgroundRemoval (createBackgroundSubtractorKNN)\n",
    "- Identify the Center of Gravity of the Object (Kalman)\n",
    "- Draw Current Box (Kalman)\n",
    "- Draw Prediction (Kalman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kalman filtering, also known as linear quadratic estimation (LQE), is an algorithm that uses a series of measurements observed over time, including statistical noise and other inaccuracies, and produces estimates of unknown variables that tend to be more accurate than those based on a single measurement alone.\n",
    "\n",
    "Used to estimate states based on linear dynamical systems in state space format. The evolution from process k-1 to k is given by:\n",
    "\n",
    "State vector x_{k-1} and the x_{k} the prediction.\n",
    "\n",
    "$x_k=Fx_{k-1}+Bu_{k-1}+w_{k-1}$\n",
    "\n",
    "- F: is the transition matrix\n",
    "- B: Control input matrix\n",
    "- w: Process noise vector (GAUSSIAN, with Q covariance)\n",
    "\n",
    "The Process and Measurement/observation model are paired following: \n",
    "\n",
    "$z_k=Hx_k+v_k$\n",
    "\n",
    "- z is the measurement vector\n",
    "- H is the measurement matrix\n",
    "- v is the noise vector Gaussian (0,R)\n",
    "\n",
    "The role of the Kalman filter is to provide estimate of xk at time k, given the initial estimate of x0, the series of measurement, z1,z2,â€¦,zk and the information of the system described by F , B , H , Q , and  R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kalman filtering has 2 steps:\n",
    "\n",
    "- Propagation (Prediction)\n",
    "\n",
    "- Measuremnet (Update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kalman(vars,dim):\n",
    "\n",
    "    PredVec=vars*dim\n",
    "\n",
    "    kalman = cv2.KalmanFilter(PredVec, dim) #6,3 Which states for position and velocity in 3D (x,y,z,vx,vy,vz)\n",
    "\n",
    "    kalman.measurementMatrix = np.array([[1,0,0,0,0,0],             #Z\n",
    "                                         [0,0,1,0,0,0],\n",
    "                                         [0,0,0,0,1,0]], np.float32)\n",
    "\n",
    "\n",
    "    kalman.transitionMatrix = np.array([[1,1,0,0,0,0],              #F\n",
    "                                        [0,1,0,0,0,0],\n",
    "                                        [0,0,1,1,0,0],\n",
    "                                        [0,0,0,1,0,0],\n",
    "                                        [0,0,0,0,1,1],\n",
    "                                        [0,0,0,0,0,1]], np.float32)\n",
    "                                        \n",
    "    kalman.processNoiseCov = np.eye(6, dtype=np.float32) * 0.03\n",
    "    kalman.measurementNoiseCov = np.eye(3, dtype=np.float32) * 0.06\n",
    "\n",
    "    prediction = np.zeros((PredVec,1), np.float32)\n",
    "\n",
    "    return prediction, kalman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BACKGROUND REMOVAL, since the background is static, the optimal solution is to perform \"Frame Difference Method\"\n",
    "https://www.codetd.com/en/article/10747516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BkgRmv(sel=1):\n",
    "    if sel == 0:\n",
    "        print(\"BackGroundSubstractor KNN\")\n",
    "        fgbg = cv2.createBackgroundSubtractorKNN(history=1000, dist2Threshold=1000, detectShadows=False)\n",
    "    elif sel== 1:\n",
    "        print(\"BackGroundSubstractor Gaussian mixture model\")\n",
    "        fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "    elif sel == 2:\n",
    "        print(\" BackGroundSubstractor Geometric Multigrid\")\n",
    "        print(\" NEEDS TO BEINSTALLED SEPARATEDLY\")\n",
    "        #fgbg = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "    else: \n",
    "        print(\"Frame Difference method\")\n",
    "        \"\"\"\"\n",
    "        if frameNum == 1:\n",
    "    \tbgFrame = cv2.cvtColor(tmp, cv2.COLOR_BGR2GRAY)\n",
    "        elif frameNum > 1:\n",
    "            foreFrame = cv2.cvtColor(tmp, cv2.COLOR_BGR2GRAY)\n",
    "            foreFrame = cv2.absdiff(foreFrame, bgFrame)\n",
    "            _, thresh = cv2.threshold(foreFrame, 30, 255, cv2.THRESH_BINARY)\n",
    "            gaussian = cv2.GaussianBlur(thresh, (3, 3), 0)\n",
    "            cv2.imshow('gaussian', foreFrame)\n",
    "        \"\"\"\"\"\n",
    "    return fgbg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The depth function implements the computation, based on the knowledge of the disparity of the 2 pairs of pixels in the rectified image planes. \n",
    "\n",
    "The **baseline**  and the **focal lenght** are parameters of the function which condition the output.\n",
    "\n",
    "Based on the assumption that the images are undistorted, we assume the rectified stereo vision case in which both image planes are horizontal and parallel. Therefore the epipolar lines are parallel and this creates a powerful set of constrains to find the corresponding point on the right image.\n",
    "\n",
    "The point is recognised by the disparity of a sliding window through the epipolar line. The lowest Sum of Absolute Difference will determine the right point on the left.\n",
    "\n",
    "Once the point has been found on the right image, disparity can be computed as the difference of the horizontal distances between the point in each image to the center of the image.\n",
    "\n",
    "Depth can be computed from the disparity simply applying the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_abs_diff(image1, image2):\n",
    "    image1 = image1.astype('int32')\n",
    "    image2 = image2.astype('int32')\n",
    "    sad = 0\n",
    "    \n",
    "    if image1.shape == image2.shape:\n",
    "        diff = image1 - image2\n",
    "        sad = np.sum(np.absolute(diff))\n",
    "    else:\n",
    "        sad = -1\n",
    "    return sad\n",
    "\n",
    "def scan_line(span, template, search_col_min, search_col_max):\n",
    "    min_place = -1\n",
    "    min_value = float('inf')\n",
    "    \n",
    "    for i in range(search_col_min, search_col_max):\n",
    "        diff = sum_abs_diff(span[:, i:i + span.shape[0]], template)\n",
    "        if diff < min_value:\n",
    "            min_value = diff\n",
    "            min_place = i\n",
    "    return (min_place, min_value)\n",
    "\n",
    "def Depth(leftGrayImg, rightGrayImg, positionOnLeft, halfWindow, baseline = 120, focalLength = 700):\n",
    "    \"\"\"\n",
    "    The function takes 6 arguments:\n",
    "    - The 2 images that are to be used to compute the triangulation,\n",
    "    - The position of the pixel in the left image,\n",
    "    - The size of the window to prompt in the template which is also the size of the Sliding window.\n",
    "    \"\"\"\n",
    "        \n",
    "    template = leftGrayImg[positionOnLeft[0]-halfWindow:positionOnLeft[0]+halfWindow,\\\n",
    "                           positionOnLeft[1]-halfWindow:positionOnLeft[1]+halfWindow]\n",
    "    #plt.figure()\n",
    "    #plt.imshow(template)\n",
    "    \n",
    "    span = rightGrayImg[positionOnLeft[0]-halfWindow:positionOnLeft[0]+halfWindow, :]\n",
    "    #plt.figure()\n",
    "    #plt.imshow(span)\n",
    "    min_place, min_value = scan_line(span, template, positionOnLeft[1]-250, positionOnLeft[1]-50-halfWindow)\n",
    "    \n",
    "    disparity = positionOnLeft[1]-min_place\n",
    "    print(\"Disparity: \", disparity, \"mm\")\n",
    "    \n",
    "    depth = focalLength*baseline/(disparity)\n",
    "    #print(f\"Depth of pixel [{positionOnLeft[0]},{positionOnLeft[1]}] in mm: {depth}\")\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BackGroundSubstractor Gaussian mixture model\n",
      "Next Frame\n",
      "469.0422058105469\n",
      "Next Frame\n",
      "4.609872341156006\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "4.94984769821167\n",
      "Next Frame\n",
      "3.6056511402130127\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "3.201662063598633\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "3.9052248001098633\n",
      "Next Frame\n",
      "3.201662063598633\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "3.201662063598633\n",
      "Next Frame\n",
      "5.147915363311768\n",
      "Next Frame\n",
      "3.9052248001098633\n",
      "Next Frame\n",
      "16.19423484802246\n",
      "Next Frame\n",
      "28.160354614257812\n",
      "Next Frame\n",
      "24.253965377807617\n",
      "Next Frame\n",
      "26.669370651245117\n",
      "Next Frame\n",
      "9.708344459533691\n",
      "Next Frame\n",
      "14.30044937133789\n",
      "Next Frame\n",
      "8.860122680664062\n",
      "Next Frame\n",
      "6.726912021636963\n",
      "Next Frame\n",
      "6.103377819061279\n",
      "Next Frame\n",
      "Next Frame\n",
      "Next Frame\n",
      "2.8285269737243652\n",
      "Next Frame\n",
      "9.617792129516602\n",
      "Next Frame\n",
      "24.15066909790039\n",
      "Next Frame\n",
      "18.33721923828125\n",
      "Next Frame\n",
      "17.219274520874023\n",
      "Next Frame\n",
      "20.359373092651367\n",
      "Next Frame\n",
      "15.435449600219727\n",
      "Next Frame\n",
      "11.629803657531738\n",
      "Next Frame\n",
      "10.735555648803711\n",
      "Next Frame\n",
      "14.31792163848877\n",
      "Next Frame\n",
      "7.382511615753174\n",
      "Next Frame\n",
      "3.201662063598633\n",
      "Next Frame\n",
      "3.5356338024139404\n",
      "Next Frame\n",
      "2.8285269737243652\n",
      "Next Frame\n",
      "3.201662063598633\n",
      "Next Frame\n",
      "3.201662063598633\n",
      "Next Frame\n",
      "2.8285269737243652\n",
      "Next Frame\n",
      "3.5356338024139404\n",
      "Next Frame\n",
      "5.4084272384643555\n",
      "Next Frame\n",
      "6.946321964263916\n",
      "Next Frame\n",
      "6.726912021636963\n",
      "Next Frame\n",
      "6.946321964263916\n",
      "Next Frame\n",
      "7.071167945861816\n",
      "Next Frame\n",
      "7.071167945861816\n",
      "Next Frame\n",
      "8.944372177124023\n",
      "Next Frame\n",
      "13.000100135803223\n",
      "Next Frame\n",
      "14.866168975830078\n",
      "Next Frame\n",
      "14.080227851867676\n",
      "Next Frame\n",
      "14.705541610717773\n",
      "Next Frame\n",
      "21.86902618408203\n",
      "Next Frame\n",
      "14.080227851867676\n",
      "Next Frame\n",
      "40.80757522583008\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "37.272743225097656\n",
      "Next Frame\n",
      "25.811918258666992\n",
      "Next Frame\n",
      "28.93537139892578\n",
      "Next Frame\n",
      "50.42082977294922\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "17.846668243408203\n",
      "Next Frame\n",
      "15.890348434448242\n",
      "Next Frame\n",
      "15.182326316833496\n",
      "Next Frame\n",
      "16.140111923217773\n",
      "Next Frame\n",
      "15.811488151550293\n",
      "Next Frame\n",
      "27.354280471801758\n",
      "Next Frame\n",
      "68.10784912109375\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "71.431884765625\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "91.72386932373047\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "112.29435729980469\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "93.68038940429688\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "79.57801055908203\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "76.50668334960938\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "101.95154571533203\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "126.01993560791016\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "174.9956512451172\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "118.8697738647461\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "171.82290649414062\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "166.64918518066406\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "155.4379425048828\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "151.7579345703125\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "101.31643676757812\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "110.15567016601562\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "93.56558227539062\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "53.38117599487305\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "53.78497314453125\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "54.33700942993164\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "56.15122604370117\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "56.73661422729492\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "58.425506591796875\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "59.77894592285156\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "60.87106704711914\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "62.37764358520508\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "65.25936889648438\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "78.41087341308594\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "65.818359375\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "67.64142608642578\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "67.90375518798828\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "69.23063659667969\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "69.44406127929688\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "70.12462615966797\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "70.55548858642578\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "70.42448425292969\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "72.09231567382812\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "81.64249420166016\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "73.94791412353516\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "84.2215347290039\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "85.80220031738281\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "86.5544204711914\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "87.65852355957031\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "88.81451416015625\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "89.73582458496094\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "91.69115447998047\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "93.0713119506836\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "95.02904510498047\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "96.30300903320312\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "97.75489807128906\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "99.3001480102539\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "100.24105834960938\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "101.15962982177734\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "101.11884307861328\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "100.8477554321289\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "101.56050109863281\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "100.42524719238281\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "101.29422760009766\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n",
      "101.29422760009766\n",
      "Computing depth\n",
      "Disparity:  250 mm\n",
      "336.0\n",
      "Next Frame\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8t/wgrgpzyx73sgt0hyhgvgsls80000gn/T/ipykernel_2306/503890363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m    \u001b[0mrightName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleftName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m    \u001b[0mimgleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m    \u001b[0mimglft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m    \u001b[0moriginalFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "leftSet = sorted(glob.glob('./../../Data/Stereo_conveyor_without_occlusions_undistorted/left/*.png')) #= cv2.VideoCapture(CamL_id)\n",
    "\n",
    "#Create Kalman Filter for state prediction\n",
    "prediction, kalman = Kalman(2,3)\n",
    " \n",
    "#Create Background Removal\n",
    "fgbg = BkgRmv(sel=1)\n",
    "\n",
    "#Preprocess image?\n",
    "morph = True\n",
    "crop = True\n",
    "\n",
    "# New Object?\n",
    "thresholdCenter = 10\n",
    "prevCenter = (0, 0)\n",
    "prevRadius = 0\n",
    "thresholdRadius = 5\n",
    "\n",
    "# Crop the image?\n",
    "cropTop = 200\n",
    "cropBottom = 600\n",
    "cropLeft = 300\n",
    "cropRight = 1150\n",
    "\n",
    "for leftName in leftSet:\n",
    "   print(\"Next Frame\")\n",
    "   rightName = leftName.replace('left','right').replace('Left','Right')\n",
    "\n",
    "   imgleft = cv2.imread(leftName)\n",
    "   imglft = cv2.cvtColor(imgleft,cv2.COLOR_BGR2GRAY)\n",
    "   originalFrame = imgleft.copy()\n",
    "\n",
    "   \n",
    "   if morph == True:\n",
    "      # Smoothening of the image \n",
    "      # Morphological Operations: Erosion +  Dilation\n",
    "      kernel = np.ones((5,5), np.uint8) \n",
    "      imglft = cv2.morphologyEx(imgleft,cv2.MORPH_OPEN,kernel)  #Open = Erosion + Dilation\n",
    "   \n",
    "   filtered = fgbg.apply(imglft)\n",
    "   filtered = cv2.morphologyEx(filtered,cv2.MORPH_OPEN,kernel)\n",
    "\n",
    "   if crop == True:\n",
    "      #Focus the analysis in the area of interest\n",
    "      cropped = filtered[cropTop:cropBottom, cropLeft:cropRight]\n",
    "\n",
    "   cnts, _ = cv2.findContours(cropped.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "   if len(cnts) > 0:\n",
    "      # In case contours were found..\n",
    "      # Find the largest one..\n",
    "      c = max(cnts, key=cv2.contourArea)\n",
    "      ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "      M = cv2.moments(c) #Find the center of the shape\n",
    "      if M[\"m00\"] == 0.0:\n",
    "                continue #If the center of the biggest object in the filtered image is in the origin stop\n",
    "      #Recovering of the global positions\n",
    "      cX = int(M[\"m10\"] / M[\"m00\"]) + cropLeft \n",
    "      cY = int(M[\"m01\"] / M[\"m00\"]) + cropTop\n",
    "      center = (cX,cY)\n",
    "      #print(radius)\n",
    "      if radius != prevRadius:#radius > 40 and radius < 200:#and radius + thresholdRadius >= prevRadius:\n",
    "      # If the object meets the size requirements...\n",
    "         cv2.circle(originalFrame, (int(x)+cropLeft, int(y)+cropTop), int(radius),\n",
    "                    (0, 255, 255), 2)                             # Enclsoing circle\n",
    "         cv2.circle(originalFrame, center, 5, (0, 0, 255), -1)   # Center of mass\n",
    "         \n",
    "         #In order to compute the depth, we will use the stereo pair\n",
    "         #Then this depth will be used by the kalman filter for 3D state estimation\n",
    "         print(\"Computing depth\")\n",
    "         imgright = cv2.imread(rightName)\n",
    "         imrght = cv2.cvtColor(imgright, cv2.COLOR_BGR2GRAY)\n",
    "         depth = Depth(originalFrame, imrght, center, 50) # We pass the center of gravity of the object to the estimate it's depth\n",
    "         print(depth)\n",
    "         \n",
    "         cv2.putText(originalFrame, f\"Depth: {depth:.2f} mm\", (0,200), cv2.FONT_ITALIC, 1, (0,0,0))\n",
    "         \n",
    "         prevRadius = radius\n",
    "         text = \"Object found at:\"\n",
    "         colour = (0, 255, 0)\n",
    "         cv2.putText(originalFrame,\"({}, {})\".format(int(center[0]), int(center[1])), (0, 100), cv2.FONT_ITALIC, 1, colour)\n",
    "\n",
    "         #Once that the object has been found we start the correction phase of the Kalman filter\n",
    "         kalman.correct(np.array([np.float32(center[0]), np.float32(center[1]), np.float32(depth)], np.float32))\n",
    "         prevCenter = center\n",
    "      else: \n",
    "         # Object not found\n",
    "         text = \"Object not found\"\n",
    "         objectFound = False\n",
    "         colour = (0, 0, 255)\n",
    "         prevRadius = 0\n",
    "         cv2.putText(originalFrame, text, (0, 100), cv2.FONT_ITALIC, 1, colour)\n",
    "   \n",
    "   else:\n",
    "   #We will only make predictions when the object is not found\n",
    "      prediction = kalman.predict()\n",
    "      center_pred = (int(prediction[0]+prediction[1]),int(prediction[2]+prediction[3]))\n",
    "      \n",
    "      cv2.circle(originalFrame, center_pred, 5, (255, 0, 0), -1)\n",
    "      cv2.putText(originalFrame,\"({}, {}, {})\".format(prediction[0], prediction[2], prediction[4]), \n",
    "                     (0, 150), cv2.FONT_ITALIC, 1, colour)\n",
    "      \n",
    "         \n",
    "   cv2.imshow('Video', originalFrame)\n",
    "   if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "      cv2.destroyAllWindows()\n",
    "      break\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6e3ad362067ff3f45b27ad8c5fc14c3dbf9ae2cffbbef9e62be45bfd3bdc469"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
